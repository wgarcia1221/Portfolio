{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Identifying Insincere Questions</h1><h20>Wilbert Garcia, Nyjay Nelson</h20><img src=\"image.png\" width=\"500\" height=\"500\" alt=\"Insincere Questions\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem Explanation**\n",
    "\n",
    "* According to the [Kaggle](https://www.kaggle.com/c/quora-insincere-questions-classification) prompt for the insincere question is one that \"founded upon false premises, or that intend to make a statement\" rather than inquire. People use tone and context and intonation and many nonverbal queues to gauge whether or not a question is insincere. Natural Language Processing (NLP) allows computers to make sense of text data and make data driven assumptions. In this case, we are performing binary classification on whether questions are insincere or not.\n",
    "\n",
    "\n",
    "* For our project, we are experimenting with the range of techniques available for Natural Language Processing from building and training an LSTM recurrent neural network from scratch to using transfer learning models specifically transformer models like BERT in order to perform binary classification on the dataset. The goal is to train a deep neural network that classifies text questions into categories of sincere or insincere. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Background**\n",
    "\n",
    "* The dataset is from a Kaggle competition. The labeled.csv file in this dataset contains 1.3 million questions labeled either sincere or insincere. An important consideration is that the data is highly unbalanced. 94 percent of the data is labelled as sincere. \n",
    "\n",
    "\n",
    "* The data was imported using pandas.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306117</th>\n",
       "      <td>What other technical skills do you need as a c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306118</th>\n",
       "      <td>Does MS in ECE have good job prospects in USA ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306119</th>\n",
       "      <td>Is foam insulation toxic?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306120</th>\n",
       "      <td>How can one start a research project based on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306121</th>\n",
       "      <td>Who wins in a battle between a Wolverine and a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1306122 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question_text  target\n",
       "0        How did Quebec nationalists see their province...       0\n",
       "1        Do you have an adopted dog, how would you enco...       0\n",
       "2        Why does velocity affect time? Does velocity a...       0\n",
       "3        How did Otto von Guericke used the Magdeburg h...       0\n",
       "4        Can I convert montra helicon D to a mountain b...       0\n",
       "...                                                    ...     ...\n",
       "1306117  What other technical skills do you need as a c...       0\n",
       "1306118  Does MS in ECE have good job prospects in USA ...       0\n",
       "1306119                          Is foam insulation toxic?       0\n",
       "1306120  How can one start a research project based on ...       0\n",
       "1306121  Who wins in a battle between a Wolverine and a...       0\n",
       "\n",
       "[1306122 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('labeled.csv', usecols=[1,2])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Cleaning for NLP Models**\n",
    "\n",
    "* We performed data preprocessing through text preprocessing and cleaning. We removed the non alphanumeric characters and numbers from the pandas dataframe. We then proceeded to make the text lowercase. We removed stopwords from the text, we removed words that have a length less than two. We remove raw components of the text data that are not relevant and useful and make the process of training a model more difficult and confusing. We make all the words lowercase because this makes the data more uniform as we do not have separate words because of capitalization. We remove stopwords because they are the most common words in the language and they do not carry meaning essential to the classification of questions as sincere or insincere. Words that are less than two characters in length are similar to stopwords in that they are commonly conjunctions or prepositions which do not carry significant meaning in determining whether questions are insincere or not.\n",
    "\n",
    "\n",
    "* We use the Scikit Learn library to split our initial data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quebec nationalists see province nation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adopted dog would encourage people adopt shop</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>velocity affect time velocity affect space geo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>otto von guericke used magdeburg hemispheres</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>convert montra helicon mountain bike changing ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306117</th>\n",
       "      <td>technical skills need computer science undergrad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306118</th>\n",
       "      <td>ece good job prospects usa like india jobs pre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306119</th>\n",
       "      <td>foam insulation toxic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306120</th>\n",
       "      <td>one start research project based biochemistry ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306121</th>\n",
       "      <td>wins battle wolverine puma</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1306122 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question_text  target\n",
       "0                  quebec nationalists see province nation       0\n",
       "1            adopted dog would encourage people adopt shop       0\n",
       "2        velocity affect time velocity affect space geo...       0\n",
       "3             otto von guericke used magdeburg hemispheres       0\n",
       "4        convert montra helicon mountain bike changing ...       0\n",
       "...                                                    ...     ...\n",
       "1306117   technical skills need computer science undergrad       0\n",
       "1306118  ece good job prospects usa like india jobs pre...       0\n",
       "1306119                              foam insulation toxic       0\n",
       "1306120  one start research project based biochemistry ...       0\n",
       "1306121                         wins battle wolverine puma       0\n",
       "\n",
       "[1306122 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text= str(text).lower()\n",
    "    text = \" \".join([word.lower() for word in text.split() if word.lower() not in stop])\n",
    "    text = \" \".join([i for i in text.split() if len(i) > 2])\n",
    "    return text\n",
    "data['question_text'] = data['question_text'].apply(clean_text)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Pre-processing for LSTM Recurrent Neural Network**\n",
    "\n",
    "* After cleaning the data, there are a number of steps involved in preparing the data for the Natural Language Processing models. This involves processes such as extracting tokens from the questions and then encoding said tokens. \n",
    "\n",
    "\n",
    "* We get the number of unique words in the dataset as an initial step in tokenizing the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the total number of unique words in dataset\n",
    "from collections import Counter\n",
    "\n",
    "def count_unique(text):\n",
    "    count = Counter()\n",
    "    for i in text.values:\n",
    "        for word in i.split():\n",
    "            count[word] += 1\n",
    "    return count\n",
    "\n",
    "text = data.question_text\n",
    "labels = data.target\n",
    "counter = count_unique(text)\n",
    "num_words = len(counter) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(text, labels, test_size=0.2)\n",
    "\n",
    "#one percent of data\n",
    "train_s1 = text[:10449]\n",
    "test_s1 = text[10449:13062]\n",
    "train_l1 = labels[:10449]\n",
    "test_l1= labels[10449:13062]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tokenize  and Encode Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words = num_words, oov_token = '<UNK>')\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Padding makes sure that the sequences are the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "train_padded = pad_sequences(train_sequences, maxlen= 20, padding = \"post\", truncating= \"post\")\n",
    "\n",
    "#might need to do fits on texts\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = pad_sequences(test_sequences, maxlen= 20, padding = \"post\", truncating= \"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create Embedding Dictionary**\n",
    "\n",
    "* We used the GloVe 6B which stands for [Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embedding_dict = {}\n",
    "file = open('glove.6B.100d.txt', encoding = 'utf-8')\n",
    "    \n",
    "for line in file:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vectors = np.asarray(values[1:], \"float32\")\n",
    "    embedding_dict[word] = vectors\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "index_len = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((index_len,100))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i < index_len:\n",
    "        emb_vec = embedding_dict.get(word)\n",
    "        if emb_vec is not None:\n",
    "            embedding_matrix[i] = emb_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Pre-processing for Transformer Model: DistilBERT**\n",
    "\n",
    "* The BERT model differs from the LSTM model in terms of encoding because it requires a CLS token and SEP token to designate the beginning and ends of sentences. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(str(text))\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "    \n",
    "    return np.array(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'activation_13', 'vocab_layer_norm', 'vocab_projector']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "transformer_layer = transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = bert_encode(train_sentences, tokenizer, max_len=50)\n",
    "test_input = bert_encode(test_sentences, tokenizer, max_len=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Related Work**\n",
    "\n",
    "There is a significant amount of research and implementation done pertaining to Natural Language Processing and the \n",
    "\n",
    "We trained a LSTM recurrent neural network (RNN). We were inspired by the model for the simple model for a RNN.\n",
    "\n",
    "The goal of this assignment is to train a deep network but deep networks are very difficult to train as they require much more data, computing power and time. We can avoid the issues of training a network from scratch by taking advantage of large neural networks that others have already trained using training learning models.\n",
    "\n",
    "We employ a transformer model. The DistilBERT model is pre-trained using .  is a fairly comprehensive dataset. It features millions of . A model that is trained on ImageNet and performs with significant accuracy generalizes well to new data and is not subject to overfitting. This is an attractive model for the classifcation of questions as sincere or insincere that we are attempting to solve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Experiments**\n",
    "\n",
    "* We have two models that we are comparing. We have an LSTM model and are also implementing a transformer model in order to compare the two. This section provides an overview of the models we created and the rationale behind choosing said models.\n",
    "    \n",
    "    * `keras_model`: * We trained a LSTM recurrent neural network from scratch. We were inspired by the simple example that [Tensorflow](https://www.tensorflow.org/guide/keras/rnn) provides of a Recurrent Neural Network using an LSTM layer through keras. \n",
    "    \n",
    "    * `DistilBERT`: DistilBERT is a language represenation model. [DistilBERT](https://arxiv.org/abs/1910.01108) is described as a \"smaller, faster, cheaper and lighter\" version of BERT. [BERT](https://arxiv.org/abs/1810.04805) is a language representation model where BERT is an acronym for Bidirectional Encoder Representations from Transformers. BERT is effective and innovative as it can performs bidirectional training on a Transformer. BERT is an attractive model because of its performance. It has shown impressive results in Natural Language Processing tasks such as \"pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)\"[4]. But, the BERT model is large and requires alot of time and memory that are outside the capacity of the tools that we have at our disposal. Because of this, we have chosen a variation of the BERT model that is more suited for our capibilities and just as impressive as the BERT model. The DistilBERT model uses knowledge distillation during pretraining and is able to \"reduce the size of a BERT model by 40%, while retaining 97% of its language understanding capabilities and being 60% faster\" [3]. We chose the Distilbert model because it is able to perform similarly to the BERT model while being faster and more cost effecient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LSTM Model**\n",
    "\n",
    "* This is the model with the best performance given our LSTM RNN architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from keras.initializers import Constant\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will refer to the first model below as keras_model_1. This model has an input_length of 50 and 64 nodes in the LSTM layer. The model after will be referred to as keras_model_2. This model has an input length of 20 and 128 nodes in the LSTM layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 100)           15865200  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               365568    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,231,025\n",
      "Trainable params: 365,825\n",
      "Non-trainable params: 15,865,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model_1 = Sequential()\n",
    "keras_model_1.add(Embedding(index_len, 100, input_length = 20, embeddings_initializer = Constant(embedding_matrix), trainable = False))\n",
    "keras_model_1.add(LSTM(256, activation= 'relu'))\n",
    "keras_model_1.add(Dropout(0.2))\n",
    "keras_model_1.add(Dense(1, activation =\"sigmoid\"))\n",
    "keras_model_1.summary()\n",
    "keras_model_1.compile(optimizer=optimizers.Adam(learning_rate=0.0001), loss=losses.BinaryCrossentropy(),metrics=[metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Transformer Model: DistilBERT**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_word_ids (InputLayer)  [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "tf_distil_bert_model (TFDist TFBaseModelOutput(last_hi 66362880  \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice_3  [(None, 768)]             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 66,363,649\n",
      "Trainable params: 66,363,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(transformer, max_len=50):\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    sequence_output = transformer(input_word_ids)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    out = Dense(1, activation='sigmoid')(cls_token)\n",
    "    \n",
    "    model = Model(inputs=input_word_ids, outputs=out)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.0001), loss=losses.BinaryCrossentropy(),metrics=[metrics.BinaryAccuracy()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model(transformer_layer, max_len=50)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Metrics**\n",
    "* Since we are classifying between two classes, we use binary accuracy instead of categorical accuracy.\n",
    "* Because implications of false negatives and false positives are more severe and because the classes in the dataset we are using are unbalanced, we look at several metrics other than just binary accuracy to determine the best model:\n",
    "    * Precision: $\\frac{TP}{TP+FP}$\n",
    "    * Recall: $\\frac{TP}{TP+FN}$\n",
    "    * F1 score: $\\frac{2\\cdot precision * recall}{precision + recall}$\n",
    "* Since we are doing binary classification, the overall precision score is the weighted precision from each class as calculated by sklearn.\n",
    "* We have written the `print_results()` function in to print the prediction, binary accuracy, precision, recall, f1 score and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix, accuracy_score\n",
    "def print_results(y_test, predictions):\n",
    "    y_pred = np.round(np.squeeze(predictions))\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 score: \", f1)\n",
    "    print(\"Confusion Matrix: \", conf_mat)\n",
    "    return accuracy, precision, recall, f1, conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Experimental Specification**\n",
    "* In our experiments, we vary the following hyperparameters\n",
    "| num__nodes_LSTM | input_length | learning_rate | embeddings_initializer |\n",
    "|------|----|----|------|\n",
    "| 32, 64, 128, 256 | 20, 50 | .001, .0001 | Yes, No |\n",
    "\n",
    "\n",
    "* There are many more combinations of hyperparameter settings that we could have tried. But, given the time constraints of the project, we used to prior knowledge and experience to chose combinations that we believed would allow us to choose an optimal model. \n",
    "\n",
    "* One of our hyperparameter settings is whether or not we include the embeddings_initializer when building the LSTM model.\n",
    "\n",
    "* For each experiment and each model, we trained 5 epochs at a time with a batch size of 32. \n",
    "\n",
    "\n",
    "* Our results can be found in `worknyjay#.ipynb`. Each file represents a different experimental test on either the LSTM models or the DistilBERT models. We began by testing on a small subset of data and using a softmax activation. We were only getting 0.06 accuracy. We continued to vary our models and switched to a larger subset of data and a sigmoid activation in the output layers. We proceeded to test different hyperparameter configurations.  \n",
    "\n",
    "\n",
    "* We now show how the optimized models  for the LSTM and DistilBERT and the best hyperparametersettings for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 176s 18ms/step - loss: 0.1049 - binary_accuracy: 0.9584\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 177s 18ms/step - loss: 0.1053 - binary_accuracy: 0.9580\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 178s 18ms/step - loss: 0.1041 - binary_accuracy: 0.9589\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 177s 18ms/step - loss: 0.1042 - binary_accuracy: 0.9588\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 178s 18ms/step - loss: 0.1024 - binary_accuracy: 0.9595\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 177s 18ms/step - loss: 0.1022 - binary_accuracy: 0.9594\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 177s 18ms/step - loss: 0.0990 - binary_accuracy: 0.9608\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 177s 18ms/step - loss: 0.0995 - binary_accuracy: 0.9606\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 176s 18ms/step - loss: 0.1001 - binary_accuracy: 0.9598\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 176s 18ms/step - loss: 0.0994 - binary_accuracy: 0.9610\n",
      "8164/8164 [==============================] - 27s 3ms/step\n",
      "Accuracy:  0.9542654799502345\n",
      "Precision:  0.632794315815264\n",
      "Recall:  0.6344653933550328\n",
      "F1 score:  0.6336287527983072\n",
      "Confusion Matrix:  [[238947   5995]\n",
      " [  5952  10331]]\n"
     ]
    }
   ],
   "source": [
    "keras_model_1.fit(train_padded, train_labels, batch_size = 32, \n",
    "                  epochs = 10, steps_per_epoch =10000,\n",
    "                  verbose=1)\n",
    "km1pred = keras_model_1.predict(test_padded, verbose=1)\n",
    "accuracy, precision, recall, f1, conf_mat = print_results(test_labels, km1pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 101s 101ms/step - loss: 0.2343 - binary_accuracy: 0.9392\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 102s 102ms/step - loss: 0.2293 - binary_accuracy: 0.9402\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 102s 102ms/step - loss: 0.2361 - binary_accuracy: 0.9377\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 102s 102ms/step - loss: 0.2408 - binary_accuracy: 0.9358\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 102s 102ms/step - loss: 0.2299 - binary_accuracy: 0.9396\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 102s 102ms/step - loss: 0.2330 - binary_accuracy: 0.9384\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 102s 102ms/step - loss: 0.2369 - binary_accuracy: 0.9367\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 102s 102ms/step - loss: 0.1594 - binary_accuracy: 0.9379\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 102s 102ms/step - loss: 0.1435 - binary_accuracy: 0.9427\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 102s 102ms/step - loss: 0.1384 - binary_accuracy: 0.9437\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 50) for input Tensor(\"input_word_ids_3:0\", shape=(None, 50), dtype=int32), but it was called on an input with incompatible shape (None, 20).\n",
      "8164/8164 [==============================] - 126s 15ms/step\n",
      "Accuracy:  0.8998487893578333\n",
      "Precision:  0.1588507493611437\n",
      "Recall:  0.1412516121107904\n",
      "F1 score:  0.1495351407580781\n",
      "Confusion Matrix:  [[232763  12179]\n",
      " [ 13983   2300]]\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(\n",
    "    train_input, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    steps_per_epoch =1000\n",
    ")\n",
    "predictions = model.predict(test_padded, verbose=1)\n",
    "accuracy, precision, recall, f1, conf_mat = print_results(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Results and Conclusion**\n",
    "\n",
    "* Based on our experiments, the best model for classifying insincere questions is the LSTM Recurrent Neural Network keras_model_1 with __ LSTM layer nodes, a learning rate of __ , input length of and including embeddings initializer in the embedding layer of the model. In training and testing this model several times with these settings, we always had a test binary accuracy ranging from .94 to .96 and F1 score ranging from .59 to .625. This model had the highest average F1 score among different hyperparameter configurations for the keras_model. We thought that it was interesting that some models had a higher average recall with a max of 0.72 than the keras_model_1 that had a max of 0.64. F1 score is an average of both precision and recall meaning that it serves as a better metric than precision or recall individually in determining the effectiveness of the model.   \n",
    "\n",
    "\n",
    "* We note that there were significant limitations when gathering experimental results. OOM errors made data collection the most difficult part of this research process. That being said, we acknowledge that there are likely other hyperparameter settings for the keras_model that could have further optimized the model. We also note that regardless of hyperparameter settings our results for DistilBERT are inconclusive. The binary accuracy ranges from .92 to .94. This is likely due to the imbalance of classes in the dataset for both the LSTM and keras_model. For the DistilBERT model, the precision, recall and F1 score are 0 leading to unclear results in terms of how to vary hyperparameters to optimize the DistilBERT model. The DistilBERT model offers an effectively rigorous and more efficient alternative to the BERT model but we were still unable to make any conclusions given the results of our experiment. \n",
    "\n",
    "\n",
    "* Overall, we believe that our keras_model is not very effective in classifying questions as sincere or insincere. Our average F1 score on our most successful model would not place us in the top 1000 submissions for the Kaggle's Insincere Question competition. Most models had accuracy over 90 percent but this was not indicative due to the imbalance of classes. Many of our models had precision, recall and F1 scores averaging over .5 for each. Our best models seemed to represent the F1 scores, precision and recall range of our peers. \n",
    "\n",
    "\n",
    "* If we had had more time and had not had OOM errors at various points, we would have liked to run a more comprehensive set of experiments  more drastically varying the hyperparameters tested and further testing the effect of batch size and steps per epoch. We believe this might result in a much better model overall. We also were curious to possibly implement the winning submission for the competition. That being said, we put a lot of time into this project and think that given the time and memory constraints, we did the best we could."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **References**\n",
    "[1] https://www.kaggle.com/c/quora-insincere-questions-classification <br>\n",
    "[2] https://www.tensorflow.org/guide/keras/rnn <br>\n",
    "[3] https://arxiv.org/abs/1910.01108 <br>\n",
    "[4] https://arxiv.org/abs/1810.04805 <br>\n",
    "[5] https://nlp.stanford.edu/projects/glove/<br>\n",
    "[6] https://www.kaggle.com/c/quora-insincere-questions-classification/leaderboard<br>\n",
    "[7] https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
